{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671f438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198e6b5",
   "metadata": {},
   "source": [
    "## Model hyperparameters\n",
    "Define some configurations for Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad80877",
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "            (30, 61), (62, 45), (59, 119),\n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ffb1e",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "#### Batch norm and fixed padding\n",
    "\n",
    "It's useful to define batch_norm function since the model uses batch norms with shared parameters heavily. Also, same as RestNet, Yolo uses convolution with fixed padding, which means that padding is defined only by the size of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e163f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "    \"\"\"\n",
    "    performs a batch normalization using a standard set of parameters.\n",
    "    \"\"\"\n",
    "    return tf.layers.batch_normalization(\n",
    "        inputs=inputs, axis=1 if data_format == \"channels_first\" else 3,\n",
    "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
    "        scale=True, training=training)\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \"\"\"\n",
    "    RestNet implemetation of fixed padding.\n",
    "    \n",
    "    pads the input along the spatial dimensions independently of the input size\n",
    "    \n",
    "    Args:\n",
    "        inputs: Tensor input to be padded.\n",
    "        kernel_size: The kernel to be used in the conv2d or max_pool2d.\n",
    "        data_format: The input format.\n",
    "    Returns:\n",
    "        A tensor with the same format as the input.\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    \n",
    "    if data_format == \"channels_first\":\n",
    "        padded_inputs = tf.pad(inputs, [[0,0], [0,0], [pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0,0], [pad_beg, pad_end], [pad_beg, pad_end], [0,0]])\n",
    "        return padded_inputs\n",
    "    \n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "    \"\"\" Strided 2-D convolution with explicit padding.\"\"\"\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides,padding=(\"SAME\" if strides == 1 else \"VALID\"),\n",
    "        use_bias=False, data_format=data_format\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c5887",
   "metadata": {},
   "source": [
    "## Feature extraction: Darknet-53\n",
    "\n",
    "For feature extraction Yolo uses Darknet-53 neural net pretrained on ImageNet. Same as RestNet, DarkNet-53 has shortcut (residual) connections, which help information from earlier layers flow further. We omit the last 3 layers (Avgpool, connected and Softmax) since we only need the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de297641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format, strides):\n",
    "    \"\"\"Creates a residual block for Darknet.\"\"\"\n",
    "    shortcuts = inputs\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters= 2 * filters, kernel_size=3, strides=strides, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs += shortcut\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "def darknet53(inputs, training, data_format):\n",
    "    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training, data_format=data_format)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(2):\n",
    "        inputs = darknet53_residual_block(inputs, filters=64, training=training, data_format=data_format)\n",
    "        inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, apha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=128, training=training, data_format=data_format)\n",
    "        route1 = inputs\n",
    "        \n",
    "        inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha=_lEAKY_RELU)\n",
    "        \n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256, training=training, data_format=data_format)\n",
    "        route2 = inputs\n",
    "        \n",
    "        inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "        \n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512, training=training, data_format=data_format)\n",
    "        return route1, route2, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadf2bd",
   "metadata": {},
   "source": [
    "## Convolution layers\n",
    "Yolo has a large number of convolutional layers. It's useful to group them in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786f3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    \"\"\"Creates convolution operations layer = used after Darknet.\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leakt_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    route = inputs\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters= 2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    return route, inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792155bb",
   "metadata": {},
   "source": [
    "## Detection layers\n",
    "Yolo has 3 detection layers, that detect on 3 different scales using respective anchors. For each cell in the feature map the detection layer predicts n_anchors * (5 + n_classes) values using 1 * 1 convolution. For each scale we have n_anchors = 3.5 + n_classes means that respectively to each of 3 anchors we are going to predict 4 coordinates of the box, its confidence score (the probability of containing an object) and class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e450d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    \"\"\"\n",
    "    Creates Yolo final detection layer.\n",
    "    \n",
    "    Detects boxes with respect to anchors.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of labels.\n",
    "        anchors: A list of anchor sizes.\n",
    "        img_size: The input size of sizes.\n",
    "        data_format: The input format.\n",
    "    Returns:\n",
    "        Tensor output.\n",
    "    \"\"\"\n",
    "    n_anchors = len(anchors)\n",
    "    \n",
    "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes), kernel_size=1, strides=1, use_bias=True, data_format=data_format)\n",
    "    shape = inputs.get_shape(),as_list()\n",
    "    grid_shape = shape[2:4] if data_format == \"channels_first\" else shape[1:3]\n",
    "    \n",
    "    if data_format == \"channels_first\":\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1], 5 + n_classes])\n",
    "    \n",
    "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "    \n",
    "    box_centers, box_shapes, confidence, classes = tf.split(inputs, [2, 2, 1, n_classes], axis = -1)\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x, y)\n",
    "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis= -1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "    \n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "    \n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "    \n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    \n",
    "    inputs = tf.concat([box_centers, box_shapes, confidence, classes], axis=1)\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100af8d1",
   "metadata": {},
   "source": [
    "## Upsample layer\n",
    "In order to concatnate with shortcut outputs from Darknet-53 before applying detection on a different scale, we are going to upsample the feature map using nearest neighbor interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355a5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "    \"\"\" Upsamples to out_shape, using nearest neighbor interpolation.\"\"\"\n",
    "    if data_format == \"channels_first\":\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "        \n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "    \n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "    \n",
    "    if data_format == \"channels_first\":\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea46130",
   "metadata": {},
   "source": [
    "## Non-max suppression\n",
    "The model is going to produce a lot of boxes, so we need a way to discard the boxes with low confidence scores. Also, to avoid having multiple boxes for one object, we will discard the boxes with high overlap as well using non-max suppression for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa3f1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boxes(inputs):\n",
    "    \"\"\"Computes top left and bottom right points of the boxes\"\"\"\n",
    "    center_x, center_y, width, height, confidence, classes = tf.split(inputs, [1,1,1,1,1,-1], axis=-1)\n",
    "    top_left_x = center_x - width / 2\n",
    "    top_left_y = center_y - width / 2\n",
    "    bottom_right_x = center_x + width / 2\n",
    "    bottom_right_y = center_y + height / 2\n",
    "    \n",
    "    boxes = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes], axis=-1)\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold, confidence_threshold):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs non-max suppression separately for each class.\n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of classes\n",
    "        max_output_size: Max number of boxes to be selected for each class.\n",
    "        iou_threshold: Threshold for IOU.\n",
    "        condifence_threshold: Threshold for the confidence score.\n",
    "    Returns: \n",
    "        A list containing class-to-boxes dictionaries for each sample in the batch\n",
    "    \"\"\"\n",
    "    batch = tf.unstack(inputs)\n",
    "    boxes_dicts = []\n",
    "    for boxes in batch:\n",
    "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
    "        classes = tf.argmax(boxes[:, 5:], axis = -1)\n",
    "        classes = tf.expand_dims(tf.to_float(classes), axis = -1)\n",
    "        boxes = tf.concat([boxes[:, :5], classes], axis = -1)\n",
    "        boxes_dict = dict()\n",
    "        for cls in range(n_classes):\n",
    "            mask = tf.equal(boxes[:, 5], cls)\n",
    "            if mask_shape.ndims != 0:\n",
    "                class_boxes = tf.boolean_mask(boxes, mask)\n",
    "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes, [4, 1, -1], axis= -1)\n",
    "                boxes_conf_scores = tf.reshape(boxes_conf_Scores, [-1])\n",
    "                indices = tf.image.non_max_suppression(boxes_coords, boxes_conf_score, mas_output_size, iou_threshold)\n",
    "                class_boxes = tf.gather(class_boxes, indices)\n",
    "                boxes_dict[cls] = class_boxes[:, :5]\n",
    "            boxes_dict.append(boxes_dict)\n",
    "        return boxes_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4bddd",
   "metadata": {},
   "source": [
    "## Final model class\n",
    "Finally, let's define the model class using all of the layers described previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5db82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v7:\n",
    "    \"\"\"Yolo v7 model class.\"\"\"\n",
    "    def __init__(self, n_classes, model_size, max_output_size, iou_threshold, confidence_threshold, data_format=None):\n",
    "        \"\"\"\n",
    "        Creates the model.\n",
    "        Args:\n",
    "            n_classes: Number of class labels.\n",
    "            model_size: The input size of the model.\n",
    "            max_output_size: Max number of boxes to be selected for each class.\n",
    "            iou_threshold: Threshold for IOU.\n",
    "            confidence_threshold: Threshold for the confidenc score.\n",
    "            data_format: The input format.\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        if not data_format:\n",
    "            if tf.test.is_built_with_cuda():\n",
    "                data_format = \"channels_first\"\n",
    "            else:\n",
    "                data_format = \"channels_last\"\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.model_size = model_size\n",
    "        self.max_output_size = max_output_size\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.data_format = data_format\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        \"\"\"\n",
    "        Add operations to detect boxes for a batch of input images.\n",
    "        Args:\n",
    "            inputs: A Tensor representing a batch of input images.\n",
    "            training: A boolean,  whether to use in training or inference mode.\n",
    "        Returns:\n",
    "            A list containing class-to-boxes dictionaries for each sample in the batch.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"yolo_v7_model\"):\n",
    "            if self.data_format == \"channels_first\":\n",
    "                inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "                \n",
    "            inputs = inputs / 255\n",
    "            route1, route2, inputs = darknet53(inputs, training=training, data_format=self.data_format)\n",
    "            route, inputs = yolo_convolution_block(inputs, filters=512, training=training, data_format=self.data_format)\n",
    "            detect1 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[6:9], img_size=self.model_size, data_format=self.data_format)\n",
    "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1, data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training, data_format=self.data_format)\n",
    "            inputs =tf.nn.leaky_relu(inputs, alpha = _LEAKY_RELU)\n",
    "            upsample_size = route2.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size, data_format=self.data_format)\n",
    "            axis = 1 if self.data_format == \"channels_first\" else 3\n",
    "            inputs = tf.concat([inputs, route2], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(inputs, filters=256, training=training, data_format=self.data_format)\n",
    "            detect2 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[3:6], img_size=self.model_size, data_format=self.data_format)\n",
    "            inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1, data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training, data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route1.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size, data_format=self.data_format)\n",
    "            inputs = tf.concat([inputs, route1], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(inputs, filters=128, training=training, data_format=self.dat_format)\n",
    "            detect3 = yolo_layer(inputs, n_classes=self.n_classes, anchors=_ANCHORS[0:3], img_size=self.model_size, data_format=self.data_format)\n",
    "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
    "            inputs = bulid_boxes(inputs)\n",
    "            \n",
    "            boxes_dicts = non_max_suppression(\n",
    "                inputs, n_classes=self.n_classes,\n",
    "                max_output_size=self.max_output_size,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                confidence_threshold=self.confidence_threshold\n",
    "            )\n",
    "            \n",
    "            return boxes_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d61f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
