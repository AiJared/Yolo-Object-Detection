{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671f438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198e6b5",
   "metadata": {},
   "source": [
    "## Model hyperparameters\n",
    "Define some configurations for Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad80877",
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "            (30, 61), (62, 45), (59, 119),\n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ffb1e",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "#### Batch norm and fixed padding\n",
    "\n",
    "It's useful to define batch_norm function since the model uses batch norms with shared parameters heavily. Also, same as RestNet, Yolo uses convolution with fixed padding, which means that padding is defined only by the size of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e163f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "    \"\"\"\n",
    "    performs a batch normalization using a standard set of parameters.\n",
    "    \"\"\"\n",
    "    return tf.layers.batch_normalization(\n",
    "        inputs=inputs, axis=1 if data_format == \"channels_first\" else 3,\n",
    "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
    "        scale=True, training=training)\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \"\"\"\n",
    "    RestNet implemetation of fixed padding.\n",
    "    \n",
    "    pads the input along the spatial dimensions independently of the input size\n",
    "    \n",
    "    Args:\n",
    "        inputs: Tensor input to be padded.\n",
    "        kernel_size: The kernel to be used in the conv2d or max_pool2d.\n",
    "        data_format: The input format.\n",
    "    Returns:\n",
    "        A tensor with the same format as the input.\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    \n",
    "    if data_format == \"channels_first\":\n",
    "        padded_inputs = tf.pad(inputs, [[0,0], [0,0], [pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0,0], [pad_beg, pad_end], [pad_beg, pad_end], [0,0]])\n",
    "        return padded_inputs\n",
    "    \n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "    \"\"\" Strided 2-D convolution with explicit padding.\"\"\"\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides,padding=(\"SAME\" if strides == 1 else \"VALID\"),\n",
    "        use_bias=False, data_format=data_format\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c5887",
   "metadata": {},
   "source": [
    "## Feature extraction: Darknet-53\n",
    "\n",
    "For feature extraction Yolo uses Darknet-53 neural net pretrained on ImageNet. Same as RestNet, DarkNet-53 has shortcut (residual) connections, which help information from earlier layers flow further. We omit the last 3 layers (Avgpool, connected and Softmax) since we only need the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de297641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format, strides):\n",
    "    \"\"\"Creates a residual block for Darknet.\"\"\"\n",
    "    shortcuts = inputs\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters= 2 * filters, kernel_size=3, strides=strides, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs += shortcut\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "def darknet53(inputs, training, data_format):\n",
    "    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training, data_format=data_format)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(2):\n",
    "        inputs = darknet53_residual_block(inputs, filters=64, training=training, data_format=data_format)\n",
    "        inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, apha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=128, training=training, data_format=data_format)\n",
    "        route1 = inputs\n",
    "        \n",
    "        inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha=_lEAKY_RELU)\n",
    "        \n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256, training=training, data_format=data_format)\n",
    "        route2 = inputs\n",
    "        \n",
    "        inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3, strides=2, data_format=data_format)\n",
    "        inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "        \n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512, training=training, data_format=data_format)\n",
    "        return route1, route2, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadf2bd",
   "metadata": {},
   "source": [
    "## Convolution layers\n",
    "Yolo has a large number of convolutional layers. It's useful to group them in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786f3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    \"\"\"Creates convolution operations layer = used after Darknet.\"\"\"\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leakt_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    route = inputs\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters= 2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    return route, inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792155bb",
   "metadata": {},
   "source": [
    "## Detection layers\n",
    "Yolo has 3 detection layers, that detect on 3 different scales using respective anchors. For each cell in the feature map the detection layer predicts n_anchors * (5 + n_classes) values using 1 * 1 convolution. For each scale we have n_anchors = 3.5 + n_classes means that respectively to each of 3 anchors we are going to predict 4 coordinates of the box, its confidence score (the probability of containing an object) and class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e450d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    \"\"\"\n",
    "    Creates Yolo final detection layer.\n",
    "    \n",
    "    Detects boxes with respect to anchors.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of labels.\n",
    "        anchors: A list of anchor sizes.\n",
    "        img_size: The input size of sizes.\n",
    "        data_format: The input format.\n",
    "    Returns:\n",
    "        Tensor output.\n",
    "    \"\"\"\n",
    "    n_anchors = len(anchors)\n",
    "    \n",
    "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes), kernel_size=1, strides=1, use_bias=True, data_format=data_format)\n",
    "    shape = inputs.get_shape(),as_list()\n",
    "    grid_shape = shape[2:4] if data_format == \"channels_first\" else shape[1:3]\n",
    "    \n",
    "    if data_format == \"channels_first\":\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1], 5 + n_classes])\n",
    "    \n",
    "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "    \n",
    "    box_centers, box_shapes, confidence, classes = tf.split(inputs, [2, 2, 1, n_classes], axis = -1)\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x, y)\n",
    "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis= -1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "    \n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "    \n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "    \n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    \n",
    "    inputs = tf.concat([box_centers, box_shapes, confidence, classes], axis=1)\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54c9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
